{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e280a939-278a-48ea-a97a-169c41a85cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fire\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "import torch\n",
    "import os\n",
    "from docx import Document\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import ast\n",
    "import sqlite3\n",
    "import warnings\n",
    "import time\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a03ac5-e2c1-41b1-8567-0406ac465960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключение к базе данных SQLite\n",
    "conn = sqlite3.connect('buhpulse_data.sqlite')\n",
    "\n",
    "# Создание курсора\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Запрос списка таблиц\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "# Получение результатов\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Закрытие соединения с базой данных\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f3a87-e2ef-4319-a82e-74ae321204c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключение к базе данных SQLite\n",
    "conn = sqlite3.connect('buhpulse_data.sqlite')\n",
    "df = pd.DataFrame()\n",
    "for i in tqdm(tables):\n",
    "    # Запрос данных из таблицы\n",
    "    query = f\"SELECT * FROM {i[0]}\"\n",
    "    \n",
    "    # Чтение данных в DataFrame\n",
    "    df_forum = pd.read_sql_query(query, conn)\n",
    "    df_forum['messages'] = i[0]\n",
    "    df = pd.concat([df, df_forum])\n",
    "    \n",
    "conn.close()\n",
    "df.shape    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63bd41c-0edf-4dfa-971d-e08b0bc56247",
   "metadata": {},
   "source": [
    "# Иcпользуемый prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf7b8e-35d4-4706-a68f-cf9912319d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Ты — эксперт в области бухгалтерии. Твоя задача — классифицировать темы, связанные с бухгалтерским учетом, налогами, отчетностью и т. д.\n",
    "Дан текст из чата, который может содержать информацию, релевантную бухгалтерам или работе предприятия. Ваша задача — структурировать информацию, извлекая ключевые темы и детали.\n",
    "Каждую полученную тему нужно отнести к одной из следующих категорий:\n",
    "1. Налоги и налогообложение\n",
    "2. Бухгалтерский учет\n",
    "3. Финансовая отчетность\n",
    "4. Внутренний контроль и аудит\n",
    "5. Финансовое планирование и прогнозирование\n",
    "6. Учет заработной платы и кадровое делопроизводство\n",
    "7. Программное обеспечение для бухгалтерии и автоматизация\n",
    "8. Взаимодействие с государственными органами\n",
    "9. Правовые аспекты бухгалтерии и налогообложения\n",
    "10. Страхование и управление финансовыми рисками\n",
    "11. Инвестиции и управление активами\n",
    "12. Учет операций с ценными бумагами и финансовыми активами\n",
    "\n",
    "Пожалуйста, отнеси каждую тему к одной из этих категорий.\n",
    "Требуется:\n",
    "1. Общая тема: Укажите основную тему обсуждения. Приведите ключевые слова или категории, о чем идет речь.  \n",
    "2. Что обсуждается: Описание конкретных аспектов, процессов, действий или деталей, связанных с указанной темой.\n",
    "\n",
    "Инструкция:\n",
    "- Если текст **содержит данные о бухгалтерии или деятельности предприятия**, верните извлеченную информацию в следующем формате:\n",
    "  ```\n",
    "  {\n",
    "    \"Тема\": [\"Категория 1\", \"Категория 2\", ...],\n",
    "    \"Описание\": [\"Описание темы 1\", \"Описание темы 2\", ...]\n",
    "  }\n",
    "  ```\n",
    "\n",
    "- Если текст не связан с работой предприятия или содержит несущественные или ошибочные данные, верните:\n",
    "  \n",
    "```\n",
    "  {\"Тема\": \"\",\n",
    "    \"Описание\": \"\"\n",
    "  }\n",
    "  ```\n",
    "Дополнительные требования:\n",
    "- Если текст неоднозначен или содержит ошибки, извлеките максимально релевантную информацию, стараясь точно классифицировать тему.\n",
    "- Игнорируйте неформальные комментарии, такие как обсуждение погоды, извинения или просьбы уточнить вопрос, если они не содержат полезной информации для анализа.\n",
    "- В случае ошибок или некорректных данных в тексте, постарайтесь извлечь суть вопроса или темы и классифицировать ее как можно точнее.\n",
    "\n",
    "Примеры:\n",
    "\n",
    "Текст:  \n",
    "\"Мы обсуждали налоговые изменения и их влияние на бухгалтерию, а также подготовку отчетности за третий квартал.\" \n",
    "Ответ:\n",
    "```\n",
    "{\n",
    "  \"Тема\": [\"Налоги (налог на прибыль, НДС, налог на имущество, НДФЛ, социальные взносы, экологические налоги, таможенные пошлины, местные налоги)\", \"Финансовая отчетность (составление отчетности, баланс, отчет о прибылях и убытках, отчет о движении денежных средств, примечания, МСФО, консолидированная отчетность)\"],\n",
    "  \"Описание\": [\"Влияние налоговых изменений на бухгалтерию\", \"Подготовка отчетности за третий квартал\"]\n",
    "}\n",
    "```\n",
    "\n",
    "Текст:  \n",
    "\"Погода сегодня отличная.*  \n",
    "Ответ:  \n",
    "```\n",
    "{\n",
    "  \"Тема\": \"\",\n",
    "  \"Описание\": \"\"\n",
    "}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4395cc5-c3cc-4c26-8450-0e0375815724",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7013af-e663-4143-9fd4-7a196503a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'NousResearch/Hermes-3-Llama-3.1-8B'  #название модели https://huggingface.co/\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Блок квантования\n",
    "# # # Configure 8-bit quantization\n",
    "# quantization_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True, # Используется 8-битное квантован\n",
    "#     bnb_8bit_quant_type='nf4',  # 'nf4'\n",
    "# )\n",
    "\n",
    "# # # # Configure 4-bit quantization\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=False,  # Не используется 8-битное квантование\n",
    "    load_in_4bit=True,   # Включаем 4-битное квантование\n",
    "    bnb_4bit_quant_type='fp4',  # 4-битное квантование с плавающей точкой\n",
    ")\n",
    "\n",
    "# # Load model with quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},  # Использование bfloat16 в пайплайне\n",
    "    device_map=\"auto\",                             # Автоматическое распределение модели по устройствам\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    truncation=True,\n",
    ")\n",
    "\n",
    "# Функция для инференса LLM\n",
    "def interact(\n",
    "    user_message,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    temperature=0.3,\n",
    "    max_length=1024\n",
    "):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\")\n",
    "    pad_token_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            model_inputs.input_ids,\n",
    "            max_new_tokens=512,\n",
    "            temperature=temperature,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=pad_token_id\n",
    "        )\n",
    "    \n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66ac09-ae55-47d0-b28a-3b489947239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция чтения файлов\n",
    "def clean_text(text):\n",
    "    cleaned_text = re.sub(r'[^а-яА-ЯЁё]', ' ', text)\n",
    "    return cleaned_text\n",
    "df = df.drop_duplicates(subset=['text'])\n",
    "print(df.shape)\n",
    "df = df[df['text'].apply(lambda row: len(clean_text(row).split()) > 10)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'^спасибо', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'^Если вы ищете работу, заполните форму', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'Напишите вакансию сюда, пожалуйста', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'\\bПодпишитесь на канал\\b', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'\\bПодписка на каналы\\b', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'\\bИнвестируя в своё образование\\b', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'\\bпредставляю вам мини-курс\\b', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'\\bИщу подработку\\b', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'\\bИщу работу\\b', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'\\bблагодарю\\b', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'\\bпочему такой вопрос возник\\b', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'\\bНовым годом\\b', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'(http[s]?://)' , case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'^Пожалуйста, задайте свой вопрос', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'^Пожалуйста, предоставьте текст', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'\\bвопрос был другой\\b', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'(https?://)', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'\\bимеете ввиду?\\b', case=False, na=False, regex=True)]\n",
    "df = df[~df['text'].str.strip().str.contains(r'\\bМожете уточнить\\b', case=False, na=False, regex=True)]\n",
    "print(df.shape)\n",
    "df = df[df['text'].str.strip().str.contains(r'(?:\\bПодскажите\\b)|(?:\\bподскажите\\b)|(?:\\bвопрос\\b)|(?:\\bВопрос\\b)|(?:\\bвопросы\\b)', case=False, na=False, regex=True)]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c67c3-6c14-4778-89d6-244e61b1693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Перемешаем, для того что бы не ждать когда все обработается, можно не делать\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902290d-8ebb-432f-b3ee-46a4d3121594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dashbord =pd.DataFrame()\n",
    "n = 0 \n",
    "start_time = time.time()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        try:\n",
    "                res = interact(row['text'].strip(), SYSTEM_PROMPT)\n",
    "                cleaned_text = res.strip('```json\\n').strip('```python\\n').strip('\\n```').replace('```', '').strip('```\\n').strip()\n",
    "                data = ast.literal_eval(cleaned_text)\n",
    "                try:\n",
    "                    data =pd.DataFrame(data)\n",
    "                except:\n",
    "                    data =pd.DataFrame([data])\n",
    "        except Exception as e:\n",
    "                print(f\"Ошибка при обработке: {res}\\n+++++++++++++++++++++++++\\n{row['text']}\\n---------------------------\\n\")\n",
    "                data = {'Тема': '', 'Описание': ''}\n",
    "                data =pd.DataFrame([data])\n",
    "        try:\n",
    "            data['id'] = row['id']\n",
    "            data['date'] = row['date']\n",
    "            data['user_id'] = row['user_id']\n",
    "            data['text'] = row['text']\n",
    "            data['messages'] = row['messages']\n",
    "\n",
    "        except Exception as e:\n",
    "            data = {'Тема': '', 'Описание': ''}\n",
    "            data =pd.DataFrame([data])\n",
    "            data['id'] = row['id']\n",
    "            data['date'] = row['date']\n",
    "            data['user_id'] = row['user_id']\n",
    "            data['text'] = row['text']\n",
    "            data['messages'] = row['messages']\n",
    "\n",
    "            \n",
    "        df_dashbord  = pd.concat([df_dashbord , data])\n",
    "        n += 1\n",
    "        if n%100 == 0:\n",
    "            df_dashbord.to_csv('После_LLM_buch_dataset.csv', index=False)\n",
    "            \n",
    "\n",
    "df_dashbord = pd.DataFrame(data_list)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "hours, remainder = divmod(elapsed_time, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print(f\"Время выполнения: {int(hours)} часов, {int(minutes)} минут, {int(seconds)} секунд\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f413fa-811d-428f-bedb-949ae0f1cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dashbord.to_csv('После_LLM_buch_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
