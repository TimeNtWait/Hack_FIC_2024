{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8da7fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь для моделей, необходмио указывать до подключения библиотек transformers\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"D:\\\\_HuggingFace\\\\models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355aa1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from Levenshtein import distance\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b79e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Profit77\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Profit77\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "import torch\n",
    "import os\n",
    "# import ast\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5340247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88a6aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d918df",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9ab02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c20045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключение к базе данных SQLite\n",
    "conn = sqlite3.connect('buhpulse_data.sqlite')\n",
    "# Создание курсора\n",
    "cursor = conn.cursor()\n",
    "# Запрос списка таблиц\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "# Получение результатов\n",
    "tables = cursor.fetchall()\n",
    "# Закрытие соединения с базой данных\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e189b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5094504626e447383d5f9ee7255739d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(323603, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Подключение к базе данных SQLite\n",
    "conn = sqlite3.connect('buhpulse_data.sqlite')\n",
    "df = pd.DataFrame()\n",
    "for i in tqdm(tables):\n",
    "    # Запрос данных из таблицы\n",
    "    query = f\"SELECT * FROM {i[0]}\"\n",
    "    \n",
    "    # Чтение данных в DataFrame\n",
    "    df_forum = pd.read_sql_query(query, conn)\n",
    "    df_forum['messages'] = i[0]\n",
    "    df = pd.concat([df, df_forum])\n",
    "    \n",
    "conn.close()\n",
    "df.shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f9f4ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2024-01-01', '2024-09-30')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'].min(), df['date'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec290f2c",
   "metadata": {},
   "source": [
    "## Анализируем  БухЭксперт8\n",
    "Уметь находить мнения о компании «БухЭксперт8» и определять их качество (положительно, нейтрально/упоминание, отрицательно)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ead0801",
   "metadata": {},
   "source": [
    "## Ищем все упомниннаия БухЭксперт8\n",
    "Используем расстояние Левенштейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aab6100d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe049b18b0e484682ff036bc4d056c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323603 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(164, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Список слов, с которыми сравниваем\n",
    "word_list = ['БухЭксперт8', 'buhexpert8']\n",
    "word_list = list(map(str.lower,word_list))\n",
    "\n",
    "\n",
    "# Максимальное расстояние Левенштейна для слова\n",
    "max_distance = 3\n",
    "\n",
    "# Функция для проверки, содержит ли предложение похожее слово\n",
    "def contains_similar_word(sentence, word_list, max_distance):\n",
    "    words = sentence.split()  # Разбиваем предложение на слова\n",
    "    return any(\n",
    "        distance(word.lower().strip('.,!?'), target_word) <= max_distance\n",
    "        for word in words\n",
    "        for target_word in word_list\n",
    "    )\n",
    "\n",
    "# Применяем фильтр к датафрейму\n",
    "df['contains_similar_buhexpert'] = df['text'].progress_apply(\n",
    "    lambda x: contains_similar_word(x, word_list, max_distance)\n",
    ")\n",
    "\n",
    "# Дополнительно ищем четкие совпадение которые не определились через расстояние Ливенштейна и формируем список найденных \n",
    "filtered_df = df[df['contains_similar_buhexpert'] |\n",
    "    ((df['text'].str.lower().str.contains('бух эксперт')) | \n",
    "    (df['text'].str.lower().str.contains('бухэксперт')) | \n",
    "    (df['text'].str.lower().str.contains('buhexpert')) | \n",
    "    (df['text'].str.lower().str.contains('buh expert'))\n",
    "    )\n",
    "]\n",
    "# # Отбираем строки с подходящими предложениями\n",
    "# filtered_df = df[df['contains_similar_buhexpert']]\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bac6a3",
   "metadata": {},
   "source": [
    "## Анализ тональности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc8b3b",
   "metadata": {},
   "source": [
    "### Загрзука модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ae50df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an assistant that always provides responses in JSON format.\n",
    "Вам предоставлен текст комментария пользователя о сервисе бухгалтерского учета. \n",
    "Ваша задача — определить, является ли этот комментарий положительным или отрицательным, с разделением на 5 категорий: \n",
    "- Очень положительный – very_positive\n",
    "- Положительный – positive\n",
    "- Нейтральный – neutral\n",
    "- Отрицательный – negative - пользователь не доволен именно сервисом, или например сервис очень дорогой\n",
    "- Очень отрицательный – very_negative - пользователь не доволен именно сервисом, или не смог что-то там найти\n",
    "Старайся использовать все 5 категорий.\n",
    "\n",
    "Если пользователь ссылается на сервис с целью предоставления достоверной информации, то это считается хорошим примером для сервиса.\n",
    "Если пользователь в комментариях высказывается негативно, но при этом он ссылается на сервис только как на источник инфомрации, то этот комментарий положительным.\n",
    "Если пользователь в комментариях высказывается негативно, но при этом он ссылается на бухэксперт (buhexpert8) на статью или на урок или на другой материал, то этот комментарий положительным.\n",
    "\n",
    "Также отразите долю привлекательности сервисом от 0 до 1, где 0 - очень отрицательный (very_negative), 0.5 - нейтральный (neutral), а 1 - очень положительный (very_positive).\n",
    "Если пользователь ссылается на сайт или советует посмотреть сервис, тогда это положительный комментарий.\n",
    "\n",
    "Также отразите основные причины, по которым пользователи оценивали сервис тем или иным образом (например, удобство интерфейса, поддержка клиентов, цена и т.д.).\n",
    "\n",
    "Результат должен быть представлен в формате JSON:\n",
    "\n",
    "Верните извлеченную информацию в следующем формате:\n",
    "```{{\"emotion\": \"positive\", \"emotion_score\": 0.65, \"reason\": \"Основная причина, по которой пользователь оценивал сервис\"}}```\n",
    "\n",
    "Ensure the output is valid JSON and matches the specified schema, if provided.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dddb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b74f2cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f860d0f79df24a588b6b9b9a97fb06c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3a50f084334bbc890d8a4577275ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = 'NousResearch/Hermes-3-Llama-3.1-8B'  #название модели https://huggingface.co/\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Блок квантования\n",
    "# # # Configure 8-bit quantization\n",
    "# quantization_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True, # Используется 8-битное квантован\n",
    "#     bnb_8bit_quant_type='nf4',  # 'nf4'\n",
    "# )\n",
    "\n",
    "# # # # # Configure 4-bit quantization\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=False,  # Не используется 8-битное квантование\n",
    "    load_in_4bit=True,   # Включаем 4-битное квантование\n",
    "    bnb_4bit_quant_type='fp4',  # 4-битное квантование с плавающей точкой\n",
    ")\n",
    "\n",
    "# Load model with quantization configuration\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},  # Использование bfloat16 в пайплайне\n",
    "    device_map=\"auto\",                             # Автоматическое распределение модели по устройствам\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    truncation=True,\n",
    ")\n",
    "\n",
    "# Функция для инференса LLM\n",
    "def interact(\n",
    "    user_message,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    temperature=0.1,\n",
    "    max_length=512\n",
    "):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\")\n",
    "    pad_token_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            model_inputs.input_ids,\n",
    "            max_new_tokens=512,\n",
    "            temperature=temperature,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=pad_token_id\n",
    "        )\n",
    "    \n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c93533a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_response(text:str):\n",
    "    try_count = 3\n",
    "    is_good_result = False\n",
    "    while try_count > 0 and is_good_result == False:\n",
    "        assistant_response = interact(text.strip(), SYSTEM_PROMPT)\n",
    "        try_count -= 1\n",
    "        try:\n",
    "            json_result = json.loads(assistant_response)\n",
    "            is_good_result = True\n",
    "            # print(json.dumps(json_result, indent=4))  # Вывод с форматированием\n",
    "        except json.JSONDecodeError as e:\n",
    "            try:\n",
    "                assistant_response = assistant_response.replace('```', '').replace('JSON', '').replace('json', '').strip()\n",
    "                if assistant_response[-1] != '}':\n",
    "                    assistant_response += '}'\n",
    "                json_result = json.loads(assistant_response)\n",
    "                is_good_result = True\n",
    "            except json.JSONDecodeError as e:    \n",
    "                try:\n",
    "                    assistant_response = assistant_response.replace('```', '').replace('JSON', '').replace('json', '').replace('\"','\"\"').strip()\n",
    "                    if assistant_response[-1] != '}':\n",
    "                        assistant_response += '}'\n",
    "                    json_result = json.loads(assistant_response)\n",
    "                    is_good_result = True\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(\"Error: Invalid JSON response\")\n",
    "                    print(assistant_response)\n",
    "    if not is_good_result:\n",
    "        print('Не получилось обработать часть данных')\n",
    "        return None, None, None\n",
    "    return json_result[\"emotion\"], json_result[\"emotion_score\"], json_result[\"reason\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "605af08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6cd6a7fa0a145f693d5b4359bd93d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Profit77\\AppData\\Local\\Temp\\ipykernel_7648\\3635577209.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['clear_text'] = filtered_df['text'].progress_apply(lambda x: clean_text(re.sub(url_pattern, standard_phrase, x)))\n"
     ]
    }
   ],
   "source": [
    "# Чистим текст \n",
    "import re\n",
    "def clean_text(text):\n",
    "    # оставляем только слова и цифры\n",
    "    pattern = r\"[a-zA-Z]+|[\\d]+|[а-яА-ЯЁё]+\"\n",
    "    text = \" \".join(re.findall(pattern, text.lower()))\n",
    "    return text\n",
    "# Заменяем ссылки\n",
    "# Регулярное выражение для поиска ссылок\n",
    "url_pattern = r'https?://[^\\s]+'\n",
    "# Заменяем ссылки на стандартную фразу\n",
    "standard_phrase = \"[ссылка на БухЭксперт8]\"\n",
    "# updated_text = \n",
    "filtered_df['clear_text'] = filtered_df['text'].progress_apply(lambda x: clean_text(re.sub(url_pattern, standard_phrase, x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0830d52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd3f8fa7b4d4213a61d9b5295251676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "C:\\Users\\Profit77\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\generation\\utils.py:2097: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Profit77\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\llama\\modeling_llama.py:602: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1h 13min 28s\n",
      "Wall time: 13min 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<timed exec>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "<timed exec>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Производим расчет\n",
    "filtered_df[['emotion', 'emotion_score', 'reason']] = filtered_df['clear_text'].progress_apply(lambda x: pd.Series(extract_response(x.strip())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bfe7fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "positive    139\n",
       "negative     15\n",
       "neutral      10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5952ab83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохрнаяем результат\n",
    "filtered_df.to_csv('emotion_buhexpert8_df_v2.csv')\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f598770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "      <th>messages</th>\n",
       "      <th>contains_similar_buhexpert</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_score</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4834</th>\n",
       "      <td>4835</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>128</td>\n",
       "      <td>Это с сайта бухэксперт приведен пример</td>\n",
       "      <td>messages_2</td>\n",
       "      <td>True</td>\n",
       "      <td>это с сайта бухэксперт приведен пример</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Пользователь ссылается на сервис бухэксперт ка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10825</th>\n",
       "      <td>10826</td>\n",
       "      <td>2024-01-19</td>\n",
       "      <td>31</td>\n",
       "      <td>Бухэксперт - подробно целая тема..)))</td>\n",
       "      <td>messages_2</td>\n",
       "      <td>True</td>\n",
       "      <td>бухэксперт подробно целая тема</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Пользователь ссылается на бухгалтерский экспер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10883</th>\n",
       "      <td>10884</td>\n",
       "      <td>2024-01-19</td>\n",
       "      <td>547</td>\n",
       "      <td>В Бухэксперте есть</td>\n",
       "      <td>messages_2</td>\n",
       "      <td>True</td>\n",
       "      <td>в бухэксперте есть</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Пользователь ссылается на сервис Buhexpert как...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10937</th>\n",
       "      <td>10938</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>13</td>\n",
       "      <td>Ну есть стаж, а там о выплатах фсс инфа, это ч...</td>\n",
       "      <td>messages_2</td>\n",
       "      <td>True</td>\n",
       "      <td>ну есть стаж а там о выплатах фсс инфа это что...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Пользователь не доволен именно сервисом, но сс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11171</th>\n",
       "      <td>11172</td>\n",
       "      <td>2024-01-20</td>\n",
       "      <td>13</td>\n",
       "      <td>Если вам это поможет https://buhexpert8.ru/1s-...</td>\n",
       "      <td>messages_2</td>\n",
       "      <td>False</td>\n",
       "      <td>если вам это поможет ссылка на бухэксперт 8</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Пользователь ссылается на сервис Buhexpert 8 к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9777</th>\n",
       "      <td>9778</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>64</td>\n",
       "      <td>Здравствуйте. На сайте Бухэксперт8 есть подроб...</td>\n",
       "      <td>messages_13</td>\n",
       "      <td>True</td>\n",
       "      <td>здравствуйте на сайте бухэксперт 8 есть подроб...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Пользователь ссылается на сервис бухэксперт 8 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11227</th>\n",
       "      <td>11228</td>\n",
       "      <td>2024-08-20</td>\n",
       "      <td>796</td>\n",
       "      <td>Долго будем Так гадать... Вот вам ссылка... Мо...</td>\n",
       "      <td>messages_13</td>\n",
       "      <td>False</td>\n",
       "      <td>долго будем так гадать вот вам ссылка может де...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.60</td>\n",
       "      <td>Пользователь высказывается негативно, но ссыла...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11569</th>\n",
       "      <td>11570</td>\n",
       "      <td>2024-08-28</td>\n",
       "      <td>57</td>\n",
       "      <td>Добрый) https://buhexpert8.ru/1s-buhgalteriya/...</td>\n",
       "      <td>messages_13</td>\n",
       "      <td>False</td>\n",
       "      <td>добрый ссылка на бухэксперт 8</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Пользователь ссылается на сервис Buhexpert 8 к...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11832</th>\n",
       "      <td>11833</td>\n",
       "      <td>2024-09-07</td>\n",
       "      <td>91</td>\n",
       "      <td>Вы быстрее и по шагам найдёте подробный ответ ...</td>\n",
       "      <td>messages_13</td>\n",
       "      <td>True</td>\n",
       "      <td>вы быстрее и по шагам найдёте подробный ответ ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.70</td>\n",
       "      <td>Пользователь использует сервис как источник ин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>12496</td>\n",
       "      <td>2024-09-23</td>\n",
       "      <td>64</td>\n",
       "      <td>Посмотрите здесь. https://buhexpert8.ru/1s-zup...</td>\n",
       "      <td>messages_13</td>\n",
       "      <td>False</td>\n",
       "      <td>посмотрите здесь ссылка на бухэксперт 8 может ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Пользователь ссылается на сервис Buhexpert 8 к...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        date  user_id  \\\n",
       "4834    4835  2024-01-12      128   \n",
       "10825  10826  2024-01-19       31   \n",
       "10883  10884  2024-01-19      547   \n",
       "10937  10938  2024-01-20       13   \n",
       "11171  11172  2024-01-20       13   \n",
       "...      ...         ...      ...   \n",
       "9777    9778  2024-07-23       64   \n",
       "11227  11228  2024-08-20      796   \n",
       "11569  11570  2024-08-28       57   \n",
       "11832  11833  2024-09-07       91   \n",
       "12495  12496  2024-09-23       64   \n",
       "\n",
       "                                                    text     messages  \\\n",
       "4834              Это с сайта бухэксперт приведен пример   messages_2   \n",
       "10825              Бухэксперт - подробно целая тема..)))   messages_2   \n",
       "10883                                 В Бухэксперте есть   messages_2   \n",
       "10937  Ну есть стаж, а там о выплатах фсс инфа, это ч...   messages_2   \n",
       "11171  Если вам это поможет https://buhexpert8.ru/1s-...   messages_2   \n",
       "...                                                  ...          ...   \n",
       "9777   Здравствуйте. На сайте Бухэксперт8 есть подроб...  messages_13   \n",
       "11227  Долго будем Так гадать... Вот вам ссылка... Мо...  messages_13   \n",
       "11569  Добрый) https://buhexpert8.ru/1s-buhgalteriya/...  messages_13   \n",
       "11832  Вы быстрее и по шагам найдёте подробный ответ ...  messages_13   \n",
       "12495  Посмотрите здесь. https://buhexpert8.ru/1s-zup...  messages_13   \n",
       "\n",
       "       contains_similar_buhexpert  \\\n",
       "4834                         True   \n",
       "10825                        True   \n",
       "10883                        True   \n",
       "10937                        True   \n",
       "11171                       False   \n",
       "...                           ...   \n",
       "9777                         True   \n",
       "11227                       False   \n",
       "11569                       False   \n",
       "11832                        True   \n",
       "12495                       False   \n",
       "\n",
       "                                              clear_text   emotion  \\\n",
       "4834              это с сайта бухэксперт приведен пример  positive   \n",
       "10825                     бухэксперт подробно целая тема  positive   \n",
       "10883                                 в бухэксперте есть  positive   \n",
       "10937  ну есть стаж а там о выплатах фсс инфа это что...  positive   \n",
       "11171        если вам это поможет ссылка на бухэксперт 8  positive   \n",
       "...                                                  ...       ...   \n",
       "9777   здравствуйте на сайте бухэксперт 8 есть подроб...  positive   \n",
       "11227  долго будем так гадать вот вам ссылка может де...  negative   \n",
       "11569                      добрый ссылка на бухэксперт 8  positive   \n",
       "11832  вы быстрее и по шагам найдёте подробный ответ ...  positive   \n",
       "12495  посмотрите здесь ссылка на бухэксперт 8 может ...  positive   \n",
       "\n",
       "       emotion_score                                             reason  \n",
       "4834            0.75  Пользователь ссылается на сервис бухэксперт ка...  \n",
       "10825           0.70  Пользователь ссылается на бухгалтерский экспер...  \n",
       "10883           0.50  Пользователь ссылается на сервис Buhexpert как...  \n",
       "10937           0.50  Пользователь не доволен именно сервисом, но сс...  \n",
       "11171           0.70  Пользователь ссылается на сервис Buhexpert 8 к...  \n",
       "...              ...                                                ...  \n",
       "9777            0.70  Пользователь ссылается на сервис бухэксперт 8 ...  \n",
       "11227           0.60  Пользователь высказывается негативно, но ссыла...  \n",
       "11569           0.70  Пользователь ссылается на сервис Buhexpert 8 к...  \n",
       "11832           0.70  Пользователь использует сервис как источник ин...  \n",
       "12495           0.50  Пользователь ссылается на сервис Buhexpert 8 к...  \n",
       "\n",
       "[164 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e68397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04220238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cda54e-c887-41c3-971c-46127e3cfeff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9cf325-a29b-49f0-bbd2-969b2e991b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d9d0e-b502-41ef-8f51-03eeba1ddc5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02b26d619a494eadba60bc5a6c87d8c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ab7a79c3943f4abe89aecddc629fc86e",
       "style": "IPY_MODEL_5b8ae9f998ae495fa6bd62626f76ca3f",
       "value": " 4/4 [00:03&lt;00:00,  1.27it/s]"
      }
     },
     "1088f9dc6f184bdc903f34c8117ad35a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_651560e90ffa41db87268d4833b7f430",
       "max": 12,
       "style": "IPY_MODEL_b9d394466a1343b4b37468f5e1a83a1d",
       "value": 12
      }
     },
     "110b3892835a446f91b58667e2016a11": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3347edab337d4e0d95b74efc88be2513": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "345417e015ac4d0bad25f1c8300c7112": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_b70382bdd36c48c1a7258f725d0ae52d",
        "IPY_MODEL_9152244731d74a339331e28ad624a20b",
        "IPY_MODEL_aab6545dc6a44c098f0f0043858c500d"
       ],
       "layout": "IPY_MODEL_a9af34432583409ab72454c232ac4663"
      }
     },
     "3a9f5409bce1454f9c48dc3a8091e50e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "480cd05e451845c0aa2930e3ac1fc7af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5b8ae9f998ae495fa6bd62626f76ca3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5c86c8ce70fd46a0b0a6aac18266f0ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "651560e90ffa41db87268d4833b7f430": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "67257bd7a60f426c80a9b55bee3384a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "75d7e0659371486288e072f7183883df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9152244731d74a339331e28ad624a20b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_480cd05e451845c0aa2930e3ac1fc7af",
       "max": 30005,
       "style": "IPY_MODEL_b31e533b82be4218949a604bc45bcdd9",
       "value": 159
      }
     },
     "9bac35597b4e461e9789fd7dc7679ff4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9f1db98abde0456a93242cd34117f351": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c1e14e1aa3594b15bd28ad49efa40d44",
       "style": "IPY_MODEL_5c86c8ce70fd46a0b0a6aac18266f0ae",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "a93f4db40c55420e87fc89de5324a5e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a9af34432583409ab72454c232ac4663": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aab6545dc6a44c098f0f0043858c500d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b8bad9eaa34f4488ad2135b7565452c8",
       "style": "IPY_MODEL_fd2ece7f7fd1435eb6bdc14457f4c4f4",
       "value": " 159/30005 [05:24&lt;16:17:18,  1.96s/it]"
      }
     },
     "ab7a79c3943f4abe89aecddc629fc86e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b31e533b82be4218949a604bc45bcdd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b45c1c281b4b4d67a77b64cf093fa03d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9f1db98abde0456a93242cd34117f351",
        "IPY_MODEL_fb717125e5244e9897cf8d0aacdb5248",
        "IPY_MODEL_02b26d619a494eadba60bc5a6c87d8c0"
       ],
       "layout": "IPY_MODEL_3347edab337d4e0d95b74efc88be2513"
      }
     },
     "b70382bdd36c48c1a7258f725d0ae52d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d2a459cdc0914033aa018c6a00667a50",
       "style": "IPY_MODEL_75d7e0659371486288e072f7183883df",
       "value": "  1%"
      }
     },
     "b8bad9eaa34f4488ad2135b7565452c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b9d394466a1343b4b37468f5e1a83a1d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "becbc161f6334ae48a39037fd441304f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c1e14e1aa3594b15bd28ad49efa40d44": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d2a459cdc0914033aa018c6a00667a50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "df9af74875e04be581e1f549ca9c8023": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e27875960d6e4777b29631c40b3c396d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f78de358036c4c08acda12299acb971d",
        "IPY_MODEL_1088f9dc6f184bdc903f34c8117ad35a",
        "IPY_MODEL_e4f2ab72bbb04a1797405199b6625f8b"
       ],
       "layout": "IPY_MODEL_9bac35597b4e461e9789fd7dc7679ff4"
      }
     },
     "e4f2ab72bbb04a1797405199b6625f8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_67257bd7a60f426c80a9b55bee3384a3",
       "style": "IPY_MODEL_df9af74875e04be581e1f549ca9c8023",
       "value": " 12/12 [00:00&lt;00:00, 16.81it/s]"
      }
     },
     "f78de358036c4c08acda12299acb971d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_110b3892835a446f91b58667e2016a11",
       "style": "IPY_MODEL_3a9f5409bce1454f9c48dc3a8091e50e",
       "value": "100%"
      }
     },
     "fb717125e5244e9897cf8d0aacdb5248": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_becbc161f6334ae48a39037fd441304f",
       "max": 4,
       "style": "IPY_MODEL_a93f4db40c55420e87fc89de5324a5e1",
       "value": 4
      }
     },
     "fd2ece7f7fd1435eb6bdc14457f4c4f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
